{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CT specific UNet PyTorch ",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dominicwhite/DeepFossil/blob/master/notebooks/03-UNet_1channel_input.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNGix1yuQ8Zl",
        "colab_type": "code",
        "outputId": "87fe9241-5102-4e15-f6bc-925bddeb736a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hLUtn6gQl9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt9QlWLnRId-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SegmentationToTensor():\n",
        "    def __call__(self, t):\n",
        "        t = torch.from_numpy(np.asarray(t)).unsqueeze(0)\n",
        "        return t.long() # torch.clamp(t, 1, 2) - 1\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.Grayscale(1),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "lbl_transform = transforms.Compose([\n",
        "    SegmentationToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "class CTSegmentationDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.slice_locations = {}\n",
        "        count = 0\n",
        "        for vol in os.listdir(self.root_dir):\n",
        "            im_dir = os.path.join(self.root_dir, vol, \"images\")\n",
        "            for vol_idx, im in enumerate(os.listdir(im_dir)):\n",
        "                self.slice_locations[count] = (vol_idx, vol)\n",
        "                count += 1\n",
        "        self.num_slices = count\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.num_slices\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        slice_idx, vol = self.slice_locations[idx]\n",
        "        vol_dir = os.path.join(self.root_dir, vol)\n",
        "        im_name = os.path.join(vol_dir, \"images\", f\"slice-{slice_idx}.png\")\n",
        "        image = Image.open(im_name)\n",
        "        label_name = os.path.join(vol_dir, \"labels\", f\"label-{slice_idx}.png\")\n",
        "        label = Image.open(label_name)\n",
        "#         label = np.clip(label, 1, 2) - 1\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform['image'](image)\n",
        "            label = self.transform['label'](label)\n",
        "            \n",
        "        return image, label\n",
        "\n",
        "dataset = CTSegmentationDataset(\n",
        "    '/content/gdrive/My Drive/Colab Notebooks/data/CT/simulated_volumes/128', \n",
        "    transform={'image': img_transform, 'label': lbl_transform})\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx6YSg9E-GUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, classes = next(iter(dataloader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNFnFGly-SpA",
        "colab_type": "code",
        "outputId": "5e6c4930-5267-4801-ffad-b458cea4121e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "im = images[1]\n",
        "print(im.shape)\n",
        "print(images.min(), images.max())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 128, 128])\n",
            "tensor(0.) tensor(0.9647)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e482drl0iOHh",
        "colab_type": "code",
        "outputId": "8bb163d2-01b2-4e5f-ac25-a9c76626cf14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "lb = classes[0]\n",
        "print(lb.shape)\n",
        "print(classes.min(), classes.max())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 128, 128])\n",
            "tensor(0) tensor(2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3e86IAMT2aq",
        "colab_type": "code",
        "outputId": "00519ff6-a58e-4aaa-e0dd-89858efd2d01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfQOai0BBtKV",
        "colab_type": "code",
        "outputId": "d7382c78-ae02-4a8f-abb4-a9a528a35d44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "# define the CNN architecture\n",
        "\n",
        "class DownConv(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_layers, mid_layers, out_layers, filter_size = 3, pool=True):\n",
        "        super(DownConv, self).__init__()\n",
        "        self.pool = pool\n",
        "        self.dc1 = nn.Conv2d(in_layers, mid_layers, filter_size, padding=1)\n",
        "        self.dc2 = nn.Conv2d(mid_layers, out_layers, filter_size, padding=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        if self.pool == True:\n",
        "            x = F.max_pool2d(x, 2)\n",
        "#             print(\"After pool, shape:\", x.shape)\n",
        "        x = F.relu(self.dc1(x))\n",
        "        x = F.relu(self.dc2(x))\n",
        "        return x\n",
        "\n",
        "    \n",
        "class UnetUpsample(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_layers, out_layers):\n",
        "        super(UnetUpsample, self).__init__()\n",
        "        self.up = nn.Upsample(mode='bilinear', scale_factor=2)\n",
        "        self.conv = nn.Conv2d(in_layers, out_layers, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.conv(self.up(x))\n",
        "    \n",
        "\n",
        "class UpConv(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_layers, mid_layers, out_layers, upsample_layers=0, filter_size = 3, interp=True):\n",
        "        super(UpConv, self).__init__()\n",
        "        self.interp = interp\n",
        "        self.trans_conv1 = nn.ConvTranspose2d(in_layers, mid_layers, filter_size, padding=1)\n",
        "        self.trans_conv2 = nn.ConvTranspose2d(mid_layers, out_layers, filter_size, padding=1)\n",
        "        if self.interp == True:\n",
        "            self.up = UnetUpsample(out_layers, upsample_layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.trans_conv1(x))\n",
        "        x = F.relu(self.trans_conv2(x))\n",
        "        if self.interp == True:\n",
        "            x = self.up(x)\n",
        "        return x\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = DownConv(1, 64, 64, pool=False)\n",
        "        self.conv2 = DownConv(64, 128, 128)\n",
        "        self.conv3 = DownConv(128, 256, 256)\n",
        "        self.conv4 = DownConv(256, 512, 512)\n",
        "        self.conv5 = DownConv(512, 1024, 1024)\n",
        "        \n",
        "        self.up_conv5 = UnetUpsample(1024, 512)\n",
        "        self.up_conv6 = UpConv(1024, 512, 512, 256)\n",
        "        self.up_conv7 = UpConv(512, 256, 256, 128)\n",
        "        self.up_conv8 = UpConv(256, 128, 128, 64)\n",
        "        self.up_conv9 = UpConv(128, 64, 64, interp=False)\n",
        "        \n",
        "        self.final = nn.Conv2d(64, 3, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        c1 = self.conv1(x)\n",
        "        c2 = self.conv2(c1)\n",
        "        c3 = self.conv3(c2)\n",
        "        c4 = self.conv4(c3)\n",
        "        c5 = self.conv5(c4)\n",
        "        \n",
        "        u6 = torch.cat([c4, self.up_conv5(c5)], dim=1)\n",
        "        u7 = torch.cat([c3, self.up_conv6(u6)], dim=1)\n",
        "        u8 = torch.cat([c2, self.up_conv7(u7)], dim=1)\n",
        "        u9 = torch.cat([c1, self.up_conv8(u8)], dim=1)\n",
        "        u10 = self.up_conv9(u9)\n",
        "        fin = self.final(u10)\n",
        "\n",
        "        return fin\n",
        "\n",
        "model = Net()\n",
        "for n, p in model.named_parameters():\n",
        "    print(n, p.shape)\n",
        "# print(model)\n",
        "output = model.forward(images)\n",
        "print(output.shape)\n",
        "# print(output[0])\n",
        "classes = classes #.long()\n",
        "# print(classes.shape)\n",
        "# print(classes[0])\n",
        "# print(classes.max())\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# loss = criterion(output, classes.squeeze())\n",
        "# print(loss.item())\n",
        "\n",
        "# lsoftmax = F.softmax(output, dim=1)\n",
        "# print(\"log_softmax of output:\", lsoftmax.shape)\n",
        "# pred1 = lsoftmax[0]\n",
        "# print(\" and just of image 1:\", pred1.shape)\n",
        "# print(pred1)\n",
        "# print(torch.sum(pred1, 0))\n",
        "# idx1 = torch.argmax(pred1, 0)\n",
        "# idxall = torch.argmax(lsoftmax, dim=1)\n",
        "# print(\"all:\", idxall.shape)\n",
        "# print(\"all[0]:\", idxall[0].shape)\n",
        "# print(idxall[0])\n",
        "# print(\"indexes:\", idx1.shape)\n",
        "# print(idx1)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.dc1.weight torch.Size([64, 1, 3, 3])\n",
            "conv1.dc1.bias torch.Size([64])\n",
            "conv1.dc2.weight torch.Size([64, 64, 3, 3])\n",
            "conv1.dc2.bias torch.Size([64])\n",
            "conv2.dc1.weight torch.Size([128, 64, 3, 3])\n",
            "conv2.dc1.bias torch.Size([128])\n",
            "conv2.dc2.weight torch.Size([128, 128, 3, 3])\n",
            "conv2.dc2.bias torch.Size([128])\n",
            "conv3.dc1.weight torch.Size([256, 128, 3, 3])\n",
            "conv3.dc1.bias torch.Size([256])\n",
            "conv3.dc2.weight torch.Size([256, 256, 3, 3])\n",
            "conv3.dc2.bias torch.Size([256])\n",
            "conv4.dc1.weight torch.Size([512, 256, 3, 3])\n",
            "conv4.dc1.bias torch.Size([512])\n",
            "conv4.dc2.weight torch.Size([512, 512, 3, 3])\n",
            "conv4.dc2.bias torch.Size([512])\n",
            "conv5.dc1.weight torch.Size([1024, 512, 3, 3])\n",
            "conv5.dc1.bias torch.Size([1024])\n",
            "conv5.dc2.weight torch.Size([1024, 1024, 3, 3])\n",
            "conv5.dc2.bias torch.Size([1024])\n",
            "up_conv5.conv.weight torch.Size([512, 1024, 1, 1])\n",
            "up_conv5.conv.bias torch.Size([512])\n",
            "up_conv6.trans_conv1.weight torch.Size([1024, 512, 3, 3])\n",
            "up_conv6.trans_conv1.bias torch.Size([512])\n",
            "up_conv6.trans_conv2.weight torch.Size([512, 512, 3, 3])\n",
            "up_conv6.trans_conv2.bias torch.Size([512])\n",
            "up_conv6.up.conv.weight torch.Size([256, 512, 1, 1])\n",
            "up_conv6.up.conv.bias torch.Size([256])\n",
            "up_conv7.trans_conv1.weight torch.Size([512, 256, 3, 3])\n",
            "up_conv7.trans_conv1.bias torch.Size([256])\n",
            "up_conv7.trans_conv2.weight torch.Size([256, 256, 3, 3])\n",
            "up_conv7.trans_conv2.bias torch.Size([256])\n",
            "up_conv7.up.conv.weight torch.Size([128, 256, 1, 1])\n",
            "up_conv7.up.conv.bias torch.Size([128])\n",
            "up_conv8.trans_conv1.weight torch.Size([256, 128, 3, 3])\n",
            "up_conv8.trans_conv1.bias torch.Size([128])\n",
            "up_conv8.trans_conv2.weight torch.Size([128, 128, 3, 3])\n",
            "up_conv8.trans_conv2.bias torch.Size([128])\n",
            "up_conv8.up.conv.weight torch.Size([64, 128, 1, 1])\n",
            "up_conv8.up.conv.bias torch.Size([64])\n",
            "up_conv9.trans_conv1.weight torch.Size([128, 64, 3, 3])\n",
            "up_conv9.trans_conv1.bias torch.Size([64])\n",
            "up_conv9.trans_conv2.weight torch.Size([64, 64, 3, 3])\n",
            "up_conv9.trans_conv2.bias torch.Size([64])\n",
            "final.weight torch.Size([3, 64, 1, 1])\n",
            "final.bias torch.Size([3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 3, 128, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atz_JvE5JH-3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3a6f6011-b8fc-4155-8d22-7ecb0001d1a8"
      },
      "source": [
        "bone_pixels = 0\n",
        "rock_pixels = 0\n",
        "num_im = 0\n",
        "for images, labels in dataloader:\n",
        "    bone = np.where(labels.numpy() == 2, 1, 0)\n",
        "    rock = np.where(labels.numpy() == 1, 1, 0)\n",
        "    bone_pixels += np.sum(bone)\n",
        "    rock_pixels += np.sum(rock)\n",
        "    num_im += bone.shape[0]\n",
        "total_pixels = num_im * 128 * 128\n",
        "bone_fraction = bone_pixels/total_pixels\n",
        "print(\"Bone:\", bone_fraction)\n",
        "rock_fraction = rock_pixels/total_pixels\n",
        "print(\"Rock:\", rock_fraction)\n",
        "air_fraction = (total_pixels - bone_pixels - rock_pixels)/total_pixels\n",
        "print(\"Air: \", air_fraction)\n",
        "class_weights = torch.tensor([1/air_fraction, 1/rock_fraction, 1/bone_fraction], dtype=torch.float).to('cuda')\n",
        "print(\"Class weights:\", class_weights)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bone: 0.005372142791748047\n",
            "Rock: 0.12730979919433594\n",
            "Air:  0.867318058013916\n",
            "Class weights: tensor([  1.1530,   7.8549, 186.1455], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcQD6e1mRU1N",
        "colab_type": "code",
        "outputId": "c33d2c2a-e514-49f2-b99b-4f3def83aa82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# create a complete CNN\n",
        "model = Net()\n",
        "print(model)\n",
        "\n",
        "# move tensors to GPU if CUDA is available\n",
        "if train_on_gpu:\n",
        "    model.cuda()\n",
        "\n",
        "from torch import nn, optim\n",
        "\n",
        "# class_weights = torch.tensor([1/0.00537], dtype=torch.float).to('cuda')\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(class_weights) #nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "for e in range(epochs):\n",
        "    print(\"Starting epoch\", e+1)\n",
        "    running_loss = 0\n",
        "    batch = 1\n",
        "    for images, labels in dataloader:\n",
        "#         if batch % 10 == 0: print(\"On batch:\", batch)\n",
        "        images, labels = images.to('cuda', dtype=torch.float), labels.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels.squeeze())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        batch += 1\n",
        "#         break\n",
        "    else:\n",
        "        print(f' Loss: {running_loss}')\n",
        "        ## TODO: Implement the validation pass and print out the validation accuracy\n",
        "        with torch.no_grad():\n",
        "            incorrect = 0\n",
        "            num_im = 0\n",
        "            total_bone_predictions = 0\n",
        "            total_actual_bone = 0\n",
        "            total_pixels = 0\n",
        "            for images, labels in dataloader:\n",
        "                images = images.to('cuda', dtype=torch.float)\n",
        "                prob_predictions = F.log_softmax(model(images), dim=1).cpu()\n",
        "                \n",
        "                class_predictions = torch.argmax(prob_predictions, dim=1).numpy()\n",
        "                bone_predictions = np.where(class_predictions == 2, 1, 0)\n",
        "                actual_bone = np.where(labels.numpy() == 2, 1, 0)\n",
        "                diff = np.sum(np.abs(bone_predictions - actual_bone))\n",
        "                \n",
        "                total_bone_predictions += np.sum(bone_predictions)\n",
        "                total_actual_bone += np.sum(actual_bone)\n",
        "                total_pixels += actual_bone.shape[0]*actual_bone.shape[2]*actual_bone.shape[3]\n",
        "                incorrect += diff\n",
        "                num_im += actual_bone.shape[0]\n",
        "        print(\" Predicted bone fraction\", total_bone_predictions/total_pixels)\n",
        "        print(f\" % Incorrect bone: {100 * incorrect / total_actual_bone}%\")\n",
        "#     break"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): DownConv(\n",
            "    (dc1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (dc2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (conv2): DownConv(\n",
            "    (dc1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (dc2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (conv3): DownConv(\n",
            "    (dc1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (dc2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (conv4): DownConv(\n",
            "    (dc1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (dc2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (conv5): DownConv(\n",
            "    (dc1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (dc2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (up_conv5): UnetUpsample(\n",
            "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "    (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (up_conv6): UpConv(\n",
            "    (trans_conv1): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (trans_conv2): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (up): UnetUpsample(\n",
            "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (up_conv7): UpConv(\n",
            "    (trans_conv1): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (trans_conv2): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (up): UnetUpsample(\n",
            "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (up_conv8): UpConv(\n",
            "    (trans_conv1): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (trans_conv2): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (up): UnetUpsample(\n",
            "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (up_conv9): UpConv(\n",
            "    (trans_conv1): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (trans_conv2): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (final): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n",
            "Class weights: tensor([  1.1530,   7.8549, 186.1455], device='cuda:0')\n",
            "Starting epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Loss: 50.72528086602688\n",
            " Predicted bone fraction 0.13449687957763673\n",
            " % Incorrect bone: 20021.856526601692%\n",
            "Starting epoch 2\n",
            " Loss: 36.023095175623894\n",
            " Predicted bone fraction 0.07365789413452148\n",
            " % Incorrect bone: 11319.891356446717%\n",
            "Starting epoch 3\n",
            " Loss: 35.2511814981699\n",
            " Predicted bone fraction 0.08170995712280274\n",
            " % Incorrect bone: 12435.955335428094%\n",
            "Starting epoch 4\n",
            " Loss: 32.03461328148842\n",
            " Predicted bone fraction 0.025095748901367187\n",
            " % Incorrect bone: 4304.184196978573%\n",
            "Starting epoch 5\n",
            " Loss: 28.314626518636942\n",
            " Predicted bone fraction 0.06274356842041015\n",
            " % Incorrect bone: 9700.44203014326%\n",
            "Starting epoch 6\n",
            " Loss: 28.219299025833607\n",
            " Predicted bone fraction 0.04072093963623047\n",
            " % Incorrect bone: 6523.413395821129%\n",
            "Starting epoch 7\n",
            " Loss: 25.22037947177887\n",
            " Predicted bone fraction 0.062123680114746095\n",
            " % Incorrect bone: 9590.53096873835%\n",
            "Starting epoch 8\n",
            " Loss: 22.383606500923634\n",
            " Predicted bone fraction 0.01806917190551758\n",
            " % Incorrect bone: 3224.3524879728748%\n",
            "Starting epoch 9\n",
            " Loss: 17.723955519497395\n",
            " Predicted bone fraction 0.019876670837402344\n",
            " % Incorrect bone: 3456.934902629103%\n",
            "Starting epoch 10\n",
            " Loss: 14.91687162593007\n",
            " Predicted bone fraction 0.01970062255859375\n",
            " % Incorrect bone: 3416.814897658483%\n",
            "Starting epoch 11\n",
            " Loss: 12.277026273310184\n",
            " Predicted bone fraction 0.024520683288574218\n",
            " % Incorrect bone: 4104.162894321066%\n",
            "Starting epoch 12\n",
            " Loss: 8.882322322577238\n",
            " Predicted bone fraction 0.013469886779785157\n",
            " % Incorrect bone: 2513.3727432497203%\n",
            "Starting epoch 13\n",
            " Loss: 8.723089562729001\n",
            " Predicted bone fraction 0.010264110565185548\n",
            " % Incorrect bone: 2055.603486534945%\n",
            "Starting epoch 14\n",
            " Loss: 7.388335626106709\n",
            " Predicted bone fraction 0.012090778350830078\n",
            " % Incorrect bone: 2307.297935417443%\n",
            "Starting epoch 15\n",
            " Loss: 8.17438342794776\n",
            " Predicted bone fraction 0.013532543182373047\n",
            " % Incorrect bone: 2519.532761712024%\n",
            "Starting epoch 16\n",
            " Loss: 6.283536933362484\n",
            " Predicted bone fraction 0.011684989929199219\n",
            " % Incorrect bone: 2240.7697360245693%\n",
            "Starting epoch 17\n",
            " Loss: 5.314431125298142\n",
            " Predicted bone fraction 0.009546375274658203\n",
            " % Incorrect bone: 1945.7953879746499%\n",
            "Starting epoch 18\n",
            " Loss: 4.858334963209927\n",
            " Predicted bone fraction 0.008040618896484376\n",
            " % Incorrect bone: 1736.368962028013%\n",
            "Starting epoch 19\n",
            " Loss: 4.652779463678598\n",
            " Predicted bone fraction 0.010397529602050782\n",
            " % Incorrect bone: 2063.53162557029%\n",
            "Starting epoch 20\n",
            " Loss: 4.937291919719428\n",
            " Predicted bone fraction 0.008127784729003907\n",
            " % Incorrect bone: 1752.271395856633%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}