{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple segmentation PyTorch CNN encoder-decoder",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dominicwhite/DeepFossil/blob/master/notebooks/02-Simple-CNN-Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNGix1yuQ8Zl",
        "colab_type": "code",
        "outputId": "f966a4a8-84d8-402e-b1c8-7c5a2fc9311d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hLUtn6gQl9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt9QlWLnRId-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FlattenImage():\n",
        "    def __call__(self, t):\n",
        "        return t.view((1,-1)).squeeze()\n",
        "\n",
        "class BoneOnly():\n",
        "    def __call__(self, t):\n",
        "        return t #torch.clamp(t, 1, 2)\n",
        "\n",
        "class SegmentationToTensor():\n",
        "    def __call__(self, t):\n",
        "        t = torch.from_numpy(np.asarray(t)).unsqueeze(0)\n",
        "        return torch.clamp(t, 1, 2) - 1\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    # you can add other transformations in this list\n",
        "    transforms.Grayscale(1),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "lbl_transform = transforms.Compose([\n",
        "    # you can add other transformations in this list\n",
        "#     transforms.Grayscale(1),\n",
        "    SegmentationToTensor(),\n",
        "#     BoneOnly()\n",
        "])\n",
        "\n",
        "\n",
        "class CTSegmentationDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.slice_locations = {}\n",
        "        count = 0\n",
        "        for vol in os.listdir(self.root_dir):\n",
        "            im_dir = os.path.join(self.root_dir, vol, \"images\")\n",
        "            for vol_idx, im in enumerate(os.listdir(im_dir)):\n",
        "                self.slice_locations[count] = (vol_idx, vol)\n",
        "                count += 1\n",
        "        self.num_slices = count\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.num_slices\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        slice_idx, vol = self.slice_locations[idx]\n",
        "        vol_dir = os.path.join(self.root_dir, vol)\n",
        "        im_name = os.path.join(vol_dir, \"images\", f\"slice-{slice_idx}.png\")\n",
        "        image = Image.open(im_name)\n",
        "        label_name = os.path.join(vol_dir, \"labels\", f\"label-{slice_idx}.png\")\n",
        "        label = Image.open(label_name)\n",
        "#         label = np.clip(label, 1, 2) - 1\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform['image'](image)\n",
        "            label = self.transform['label'](label)\n",
        "            \n",
        "        return image, label\n",
        "\n",
        "dataset = CTSegmentationDataset(\n",
        "    '/content/gdrive/My Drive/Colab Notebooks/data/CT/simulated_volumes/128', \n",
        "    transform={'image': img_transform, 'label': lbl_transform})\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx6YSg9E-GUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, classes = next(iter(dataloader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNFnFGly-SpA",
        "colab_type": "code",
        "outputId": "0fb64fa4-ac4f-41a8-b755-642da1a25e18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "im = images[1]\n",
        "print(im.shape)\n",
        "print(images.max())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 128, 128])\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e482drl0iOHh",
        "colab_type": "code",
        "outputId": "d62aa44e-dccf-4d11-adea-f23941e8526d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "lb = classes[0]\n",
        "print(lb.shape)\n",
        "print(classes.max())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 128, 128])\n",
            "tensor(1, dtype=torch.uint8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3e86IAMT2aq",
        "colab_type": "code",
        "outputId": "ff277301-cf2d-4cd7-b64e-c65b1b9638dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfQOai0BBtKV",
        "colab_type": "code",
        "outputId": "a8cc4eef-07ce-4a41-9f01-a12b304bf1bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "# define the CNN architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.convtc5 = nn.Conv2d(128, 64, 3, padding=1)\n",
        "        self.convtc6 = nn.Conv2d(64, 32, 3, padding=1)\n",
        "        self.convtc7 = nn.Conv2d(32, 16, 3, padding=1)\n",
        "        self.convtc8 = nn.Conv2d(16, 1, 3, padding=1)\n",
        "        self.mp = nn.MaxPool2d(2,2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mp(F.relu(self.conv1(x)))\n",
        "        x = self.mp(F.relu(self.conv2(x)))\n",
        "        x = self.mp(F.relu(self.conv3(x)))\n",
        "        x = self.mp(F.relu(self.conv4(x)))\n",
        "        x = F.relu(self.convtc5(F.interpolate(x,scale_factor=2)))\n",
        "        x = F.relu(self.convtc6(F.interpolate(x,scale_factor=2)))\n",
        "        x = F.relu(self.convtc7(F.interpolate(x,scale_factor=2)))\n",
        "        x = self.convtc8(F.interpolate(x,scale_factor=2))\n",
        "#         x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "print(model)\n",
        "output = model.forward(images)\n",
        "print(output.shape)\n",
        "print(output[0])\n",
        "print(classes.shape)\n",
        "print(classes[0])\n",
        "print(classes.max())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (convtc5): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (convtc6): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (convtc7): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (convtc8): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n",
            "torch.Size([32, 1, 128, 128])\n",
            "tensor([[[-0.0510, -0.0560, -0.0552,  ..., -0.0564, -0.0566, -0.0564],\n",
            "         [-0.0605, -0.0632, -0.0628,  ..., -0.0645, -0.0640, -0.0591],\n",
            "         [-0.0589, -0.0610, -0.0597,  ..., -0.0622, -0.0618, -0.0566],\n",
            "         ...,\n",
            "         [-0.0599, -0.0615, -0.0600,  ..., -0.0610, -0.0615, -0.0567],\n",
            "         [-0.0589, -0.0611, -0.0598,  ..., -0.0609, -0.0614, -0.0568],\n",
            "         [-0.0588, -0.0606, -0.0583,  ..., -0.0611, -0.0626, -0.0569]]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "torch.Size([32, 1, 128, 128])\n",
            "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)\n",
            "tensor(1, dtype=torch.uint8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcQD6e1mRU1N",
        "colab_type": "code",
        "outputId": "903196e6-1505-4126-f24a-1c168b280c54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# create a complete CNN\n",
        "model = Net()\n",
        "print(model)\n",
        "\n",
        "# move tensors to GPU if CUDA is available\n",
        "if train_on_gpu:\n",
        "    model.cuda()\n",
        "\n",
        "from torch import nn, optim\n",
        "\n",
        "class_weights = torch.tensor([1/0.00537], dtype=torch.float).to('cuda')\n",
        "print(class_weights)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "for e in range(epochs):\n",
        "    print(\"Starting epoch\", e+1)\n",
        "    running_loss = 0\n",
        "    for images, labels in dataloader:\n",
        "#         print(images.shape)\n",
        "#         images, labels = images.to('cuda', dtype=torch.float), labels.to('cuda', dtype=torch.long)\n",
        "        images, labels = images.to('cuda', dtype=torch.float), labels.to('cuda', dtype=torch.float)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(images)\n",
        "#         print(\"output\", output.shape)\n",
        "#         print(\"labels\", labels.shape)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "#         break\n",
        "    else:\n",
        "        print(f' Loss: {running_loss}')\n",
        "        ## TODO: Implement the validation pass and print out the validation accuracy\n",
        "        with torch.no_grad():\n",
        "            correct = []\n",
        "            num_im = 0\n",
        "#             total = torch.zeros(1)\n",
        "#             img, lbl = dataset[182]\n",
        "#             img = img.unsqueeze(0)\n",
        "#             print(\"img\", img.shape, img.sum(), img.min(), img.max())\n",
        "#             lbl = lbl.unsqueeze(0)\n",
        "#             img = img.to('cuda', dtype=torch.float)\n",
        "#             ps = torch.sigmoid(model(img)).cpu().numpy()\n",
        "#             print(\"ps\", ps.shape, ps.sum(), ps.min(), ps.max())\n",
        "#             preds = np.where(ps < 0.5, 0, 1)\n",
        "#             print(\"preds\", preds.shape, preds.sum())\n",
        "#             print(\"lbl\", lbl.shape, lbl.sum())\n",
        "            total_bone_predictions = 0\n",
        "            total_pixels = 0\n",
        "            for images, labels in dataloader:\n",
        "                images = images.to('cuda', dtype=torch.float)\n",
        "#                 ps = torch.sigmoid(model(images)).cpu().numpy()\n",
        "                ps = torch.sigmoid(model(images)).cpu().numpy()\n",
        "#                 print(\"ps\", ps.shape)\n",
        "                preds = np.where(ps < 0.5, 0, 1)\n",
        "#                 print(\"preds\", preds.shape, preds.min(), preds.max())\n",
        "                np_labels = labels.numpy()\n",
        "                diff = np.sum(np.abs(preds - np_labels))\n",
        "#                 print(\"  diff\", diff)\n",
        "                total_bone_predictions += np.sum(preds)\n",
        "                total_pixels += ps.shape[0]*ps.shape[2]*ps.shape[3]\n",
        "                correct.append(diff)\n",
        "                num_im += ps.shape[0]\n",
        "#                 top_p, top_class = ps.topk(1, dim=1)\n",
        "#                 print(\"top_p\", top_p.shape)\n",
        "#                 print(\"top_p\", top_p[0])\n",
        "#                 print(\"top_class\", top_class.shape)\n",
        "#                 print(\"top_class\", top_class[0])\n",
        "#                 equals = top_class == labels.view(*top_class.shape)\n",
        "#                 correct += torch.sum(equals)\n",
        "#                 total += len(equals)\n",
        "# #                 accuracy = accuracy + torch.mean(equals.type(torch.FloatTensor))\n",
        "#             accuracy = correct / total\n",
        "#         print(\"  sum of correct:\", sum(correct))\n",
        "        print(\" Predicted bone fraction\", total_bone_predictions/total_pixels)\n",
        "        print(f' Accuracy: {sum(correct)*100/(ps.shape[2]*ps.shape[3]*num_im)}%')\n",
        "#     break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (convtc5): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (convtc6): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (convtc7): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (convtc8): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n",
            "tensor([186.2197], device='cuda:0')\n",
            "Starting epoch 1\n",
            " Loss: 25.72144877910614\n",
            " Predicted bone fraction 0.24804344177246093\n",
            " Accuracy: 24.276037216186523%\n",
            "Starting epoch 2\n",
            " Loss: 15.136053383350372\n",
            " Predicted bone fraction 0.20147018432617186\n",
            " Accuracy: 19.62508201599121%\n",
            "Starting epoch 3\n",
            " Loss: 11.409927725791931\n",
            " Predicted bone fraction 0.1539586067199707\n",
            " Accuracy: 14.887447357177734%\n",
            "Starting epoch 4\n",
            " Loss: 10.011294573545456\n",
            " Predicted bone fraction 0.15297937393188477\n",
            " Accuracy: 14.772777557373047%\n",
            "Starting epoch 5\n",
            " Loss: 9.712061256170273\n",
            " Predicted bone fraction 0.15257863998413085\n",
            " Accuracy: 14.733867645263672%\n",
            "Starting epoch 6\n",
            " Loss: 8.981339305639267\n",
            " Predicted bone fraction 0.11929731369018555\n",
            " Accuracy: 11.42496109008789%\n",
            "Starting epoch 7\n",
            " Loss: 8.249072700738907\n",
            " Predicted bone fraction 0.12138290405273437\n",
            " Accuracy: 11.62083625793457%\n",
            "Starting epoch 8\n",
            " Loss: 7.798814803361893\n",
            " Predicted bone fraction 0.12573471069335937\n",
            " Accuracy: 12.050313949584961%\n",
            "Starting epoch 9\n",
            " Loss: 8.09140345454216\n",
            " Predicted bone fraction 0.14057979583740235\n",
            " Accuracy: 13.52442741394043%\n",
            "Starting epoch 10\n",
            " Loss: 7.721835643053055\n",
            " Predicted bone fraction 0.11803293228149414\n",
            " Accuracy: 11.278095245361328%\n",
            "Starting epoch 11\n",
            " Loss: 7.092292964458466\n",
            " Predicted bone fraction 0.10527563095092773\n",
            " Accuracy: 10.011615753173828%\n",
            "Starting epoch 12\n",
            " Loss: 6.884661480784416\n",
            " Predicted bone fraction 0.10173120498657226\n",
            " Accuracy: 9.666080474853516%\n",
            "Starting epoch 13\n",
            " Loss: 6.63329291343689\n",
            " Predicted bone fraction 0.10236082077026368\n",
            " Accuracy: 9.713878631591797%\n",
            "Starting epoch 14\n",
            " Loss: 6.207208976149559\n",
            " Predicted bone fraction 0.10348281860351563\n",
            " Accuracy: 9.821710586547852%\n",
            "Starting epoch 15\n",
            " Loss: 6.446151599287987\n",
            " Predicted bone fraction 0.0851095199584961\n",
            " Accuracy: 8.009405136108398%\n",
            "Starting epoch 16\n",
            " Loss: 5.758747652173042\n",
            " Predicted bone fraction 0.10849723815917969\n",
            " Accuracy: 10.315999984741211%\n",
            "Starting epoch 17\n",
            " Loss: 6.45709815621376\n",
            " Predicted bone fraction 0.0884552001953125\n",
            " Accuracy: 8.322610855102539%\n",
            "Starting epoch 18\n",
            " Loss: 5.692455887794495\n",
            " Predicted bone fraction 0.10506458282470703\n",
            " Accuracy: 9.973306655883789%\n",
            "Starting epoch 19\n",
            " Loss: 4.9894923865795135\n",
            " Predicted bone fraction 0.07346410751342773\n",
            " Accuracy: 6.820068359375%\n",
            "Starting epoch 20\n",
            " Loss: 4.640211910009384\n",
            " Predicted bone fraction 0.0956376075744629\n",
            " Accuracy: 9.028549194335938%\n",
            "Starting epoch 21\n",
            " Loss: 4.79003044962883\n",
            " Predicted bone fraction 0.04992752075195313\n",
            " Accuracy: 4.488401412963867%\n",
            "Starting epoch 22\n",
            " Loss: 4.3677659928798676\n",
            " Predicted bone fraction 0.07852096557617187\n",
            " Accuracy: 7.318849563598633%\n",
            "Starting epoch 23\n",
            " Loss: 5.373064294457436\n",
            " Predicted bone fraction 0.06227273941040039\n",
            " Accuracy: 5.735950469970703%\n",
            "Starting epoch 24\n",
            " Loss: 4.766499027609825\n",
            " Predicted bone fraction 0.07111005783081055\n",
            " Accuracy: 6.578826904296875%\n",
            "Starting epoch 25\n",
            " Loss: 4.204296097159386\n",
            " Predicted bone fraction 0.06390552520751953\n",
            " Accuracy: 5.85759162902832%\n",
            "Starting epoch 26\n",
            " Loss: 4.205074578523636\n",
            " Predicted bone fraction 0.07013063430786133\n",
            " Accuracy: 6.478157043457031%\n",
            "Starting epoch 27\n",
            " Loss: 3.588841736316681\n",
            " Predicted bone fraction 0.037057018280029295\n",
            " Accuracy: 3.1888580322265625%\n",
            "Starting epoch 28\n",
            " Loss: 3.319021597504616\n",
            " Predicted bone fraction 0.04675893783569336\n",
            " Accuracy: 4.144115447998047%\n",
            "Starting epoch 29\n",
            " Loss: 3.6078901141881943\n",
            " Predicted bone fraction 0.059923839569091794\n",
            " Accuracy: 5.456962585449219%\n",
            "Starting epoch 30\n",
            " Loss: 3.4665324091911316\n",
            " Predicted bone fraction 0.06740608215332031\n",
            " Accuracy: 6.204156875610352%\n",
            "Starting epoch 31\n",
            " Loss: 3.8492741137742996\n",
            " Predicted bone fraction 0.0401881217956543\n",
            " Accuracy: 3.4893226623535156%\n",
            "Starting epoch 32\n",
            " Loss: 2.962930306792259\n",
            " Predicted bone fraction 0.042919063568115236\n",
            " Accuracy: 3.7603759765625%\n",
            "Starting epoch 33\n",
            " Loss: 2.6791755333542824\n",
            " Predicted bone fraction 0.03862066268920898\n",
            " Accuracy: 3.3304786682128906%\n",
            "Starting epoch 34\n",
            " Loss: 2.54574953019619\n",
            " Predicted bone fraction 0.040452003479003906\n",
            " Accuracy: 3.511171340942383%\n",
            "Starting epoch 35\n",
            " Loss: 2.5449526235461235\n",
            " Predicted bone fraction 0.05080099105834961\n",
            " Accuracy: 4.543952941894531%\n",
            "Starting epoch 36\n",
            " Loss: 3.9215295538306236\n",
            " Predicted bone fraction 0.059261512756347653\n",
            " Accuracy: 5.39006233215332%\n",
            "Starting epoch 37\n",
            " Loss: 2.902054861187935\n",
            " Predicted bone fraction 0.030197811126708985\n",
            " Accuracy: 2.499408721923828%\n",
            "Starting epoch 38\n",
            " Loss: 2.69314668700099\n",
            " Predicted bone fraction 0.0344813346862793\n",
            " Accuracy: 2.9169082641601562%\n",
            "Starting epoch 39\n",
            " Loss: 2.5732317492365837\n",
            " Predicted bone fraction 0.02722005844116211\n",
            " Accuracy: 2.1991920471191406%\n",
            "Starting epoch 40\n",
            " Loss: 2.3423297852277756\n",
            " Predicted bone fraction 0.0381011962890625\n",
            " Accuracy: 3.2755565643310547%\n",
            "Starting epoch 41\n",
            " Loss: 2.1729035452008247\n",
            " Predicted bone fraction 0.025985050201416015\n",
            " Accuracy: 2.07244873046875%\n",
            "Starting epoch 42\n",
            " Loss: 2.235576421022415\n",
            " Predicted bone fraction 0.040620613098144534\n",
            " Accuracy: 3.5266971588134766%\n",
            "Starting epoch 43\n",
            " Loss: 2.2023906223475933\n",
            " Predicted bone fraction 0.03149213790893555\n",
            " Accuracy: 2.6168441772460938%\n",
            "Starting epoch 44\n",
            " Loss: 2.390430126339197\n",
            " Predicted bone fraction 0.033885955810546875\n",
            " Accuracy: 2.8539562225341797%\n",
            "Starting epoch 45\n",
            " Loss: 2.4144310504198074\n",
            " Predicted bone fraction 0.036066627502441405\n",
            " Accuracy: 3.072500228881836%\n",
            "Starting epoch 46\n",
            " Loss: 2.0716846100986004\n",
            " Predicted bone fraction 0.02440299987792969\n",
            " Accuracy: 1.9128894805908203%\n",
            "Starting epoch 47\n",
            " Loss: 1.904896765947342\n",
            " Predicted bone fraction 0.02542257308959961\n",
            " Accuracy: 2.011127471923828%\n",
            "Starting epoch 48\n",
            " Loss: 1.9163778387010098\n",
            " Predicted bone fraction 0.027516269683837892\n",
            " Accuracy: 2.2179222106933594%\n",
            "Starting epoch 49\n",
            " Loss: 1.84357076510787\n",
            " Predicted bone fraction 0.037097740173339847\n",
            " Accuracy: 3.1733036041259766%\n",
            "Starting epoch 50\n",
            " Loss: 1.9500488489866257\n",
            " Predicted bone fraction 0.03631267547607422\n",
            " Accuracy: 3.0947399139404297%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}